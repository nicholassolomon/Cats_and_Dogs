{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Cats v Dogs Code"
      ],
      "metadata": {
        "id": "aLjaqme3yTN8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Get Data\n"
      ],
      "metadata": {
        "id": "mvPX0jmGyaY0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile download_data.py\n",
        "import requests\n",
        "import os\n",
        "import zipfile\n",
        "from pathlib import Path\n",
        "\n",
        "def download_zip_data(url, path_to_data):\n",
        "  \"\"\"\n",
        "  Download zipped contents and unzip\n",
        "  \"\"\"\n",
        "  path = Path(url)\n",
        "  print(f\"full name: {path.name}\")\n",
        "  print(f\"name only: {path.stem}\")\n",
        "  data_path = Path(path_to_data)\n",
        "  print(str(data_path))\n",
        "\n",
        "  if data_path.is_dir():\n",
        "    print(f\"path_to_data exists\")\n",
        "  else:\n",
        "    print(f\"path doesn't exist\")\n",
        "    data_path.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    # Download pizza, steak, sushi data\n",
        "    with open(data_path / path.name, \"wb\") as f:\n",
        "        request = requests.get(url)\n",
        "        print(f\"Downloading {path.stem}\")\n",
        "        f.write(request.content)\n",
        "\n",
        "    # Unzip pizza, steak, sushi data\n",
        "    with zipfile.ZipFile(data_path / path.name, \"r\") as zip_ref:\n",
        "        print(f\"Unzipping {path.stem}\")\n",
        "        zip_ref.extractall(data_path)\n",
        "\n",
        "    os.remove(data_path / path.name)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TfIRYMdEbTXt",
        "outputId": "85b3dc6b-5e00-4b70-d612-0dd23d474194"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing download_data.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Build TF Model"
      ],
      "metadata": {
        "id": "62kOXCc7ynI9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile build_tf_model.py\n",
        "\"\"\"\n",
        "Contains TensorFlow code for Cat vs Dogs CNN model\n",
        "\"\"\"\n",
        "import tensorflow as tf\n",
        "\n",
        "def build_model(random_seed=42):\n",
        "  tf.random.set_seed(random_seed)\n",
        "\n",
        "  model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Conv2D(filters=16,\n",
        "                           kernel_size=(3,3),\n",
        "                           activation='relu',\n",
        "                           input_shape=(150,150,3)),\n",
        "    tf.keras.layers.MaxPool2D(pool_size=(2,2)),\n",
        "\n",
        "    tf.keras.layers.Conv2D(filters=32,\n",
        "                           kernel_size=(3,3),\n",
        "                           activation='relu'),\n",
        "    tf.keras.layers.MaxPool2D(pool_size=(2,2)),\n",
        "\n",
        "    tf.keras.layers.Conv2D(filters=64,\n",
        "                           kernel_size=(3,3),\n",
        "                           activation='relu'),\n",
        "    tf.keras.layers.MaxPool2D(pool_size=(2,2)),\n",
        "\n",
        "    tf.keras.layers.Flatten(),\n",
        "\n",
        "    tf.keras.layers.Dense(units=512, activation='relu'),\n",
        "    tf.keras.layers.Dropout(rate=0.5),\n",
        "\n",
        "    # output layer\n",
        "    tf.keras.layers.Dense(units=1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "# using Adam\n",
        "#model_1.compile(loss=tf.keras.losses.BinaryCrossentropy(),\n",
        "#                optimizer=tf.keras.optimizers.Adam(learng_rate=1e-3),\n",
        "#                metrix=['accuracy'])\n",
        "\n",
        "# using RMSprop\n",
        "  model.compile(loss=tf.keras.losses.BinaryCrossentropy(),\n",
        "                optimizer=tf.keras.optimizers.RMSprop(learning_rate=1e-3),\n",
        "                metrics=['accuracy'])\n",
        "\n",
        "  return model\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XSl8oq_Pa_3D",
        "outputId": "58334117-d844-49d0-adf2-250329d9d058"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing build_tf_model.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training TF Model"
      ],
      "metadata": {
        "id": "xyyMfhV41XQn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile tf_train.py\n",
        "\"\"\"\n",
        "Training code for TF model\n",
        "\"\"\"\n",
        "import tensorflow as tf\n",
        "\n",
        "def tf_model_training(model, ds_train, ds_validation, epochs)\n",
        "  history = model.fit(ds_train_ds,\n",
        "                    epochs=epochs,\n",
        "                    steps_per_epoch=len(ds_train),\n",
        "                    validation_data=ds_validataion,\n",
        "                    validation_steps=len(ds_validataion),\n",
        "                    verbose=2)\n",
        "  return history\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "43Bb5EDI1ZwQ",
        "outputId": "2249817a-ad48-48c3-9f0c-8810b64f448e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing tf_train.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Utilities"
      ],
      "metadata": {
        "id": "fpdBXTVuy_9l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile model_utilities.py\n",
        "\"\"\"\n",
        "Utilities when evaluating model and reviewing picture data\n",
        "\"\"\"\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "import random\n",
        "import pathlib\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def tf_plot_loss_curves(history):\n",
        "  \"\"\"\n",
        "  Returns separate loss curves for training and validation metrics.\n",
        "  \"\"\"\n",
        "  loss = history.history['loss']\n",
        "  val_loss = history.history['val_loss']\n",
        "\n",
        "  accuracy = history.history['accuracy']\n",
        "  val_accuracy = history.history['val_accuracy']\n",
        "\n",
        "  epochs = range(len(history.history['loss']))\n",
        "\n",
        "  # Plot loss\n",
        "  plt.plot(epochs, loss, label='training_loss')\n",
        "  plt.plot(epochs, val_loss, label='val_loss')\n",
        "  plt.title('Loss')\n",
        "  plt.xlabel('Epochs')\n",
        "  plt.legend()\n",
        "\n",
        "  # Plot accuracy\n",
        "  plt.figure()\n",
        "  plt.plot(epochs, accuracy, label='training_accuracy')\n",
        "  plt.plot(epochs, val_accuracy, label='val_accuracy')\n",
        "  plt.title('Accuracy')\n",
        "  plt.xlabel('Epochs')\n",
        "  plt.legend();\n",
        "\n",
        "\n",
        "def get_classes(dir_path):\n",
        "  \"\"\"\n",
        "  Get a list of class names based on the folder names in the image subdirectories\n",
        "  Args:\n",
        "    dir_path (str or pathlib.Path): target directory\n",
        "\n",
        "  Returns:\n",
        "    List of directory names as class names\n",
        "  \"\"\"\n",
        "  # Get the class names (programmatically, this is much more helpful with a longer list of classes)\n",
        "  data_dir = pathlib.Path(data_path) # turn our training path into a Python path\n",
        "  class_names = np.array(sorted([item.name for item in data_dir.glob('*')])) # created a list of class_names from the subdirectories\n",
        "  return class_names\n",
        "\n",
        "def walk_through_dir(dir_path):\n",
        "  \"\"\"\n",
        "  Walks through dir_path returning its contents.\n",
        "  Args:\n",
        "    dir_path (str or pathlib.Path): target directory\n",
        "\n",
        "  Returns:\n",
        "    A print out of:\n",
        "      number of subdiretories in dir_path\n",
        "      number of images (files) in each subdirectory\n",
        "      name of each subdirectory\n",
        "  \"\"\"\n",
        "  for dirpath, dirnames, filenames in os.walk(dir_path):\n",
        "    print(f\"There are {len(dirnames)} directories and {len(filenames)} images in '{dirpath}'.\")\n",
        "\n",
        "\n",
        "\n",
        ""
      ],
      "metadata": {
        "id": "MPTEt8ul9QMv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "649e96f7-6b88-4d0e-f5ae-80f6365788d6"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing model_utilities.py\n"
          ]
        }
      ]
    }
  ]
}